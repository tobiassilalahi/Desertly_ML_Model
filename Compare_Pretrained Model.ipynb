{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport random\nfrom shutil import copyfile\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import Model\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_SOURCE_DIR_IMAGES = \"/kaggle/input/dessert/Images/Training\"\nBASE_SOURCE_DIR_IMAGES_VAL = \"/kaggle/input/dessert/Images/Validation\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_size = 224","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Inception V3\n\nincnet = InceptionV3(\n    input_shape=(target_size, target_size, 3),\n    include_top=False,\n    weights = \"imagenet\"\n)\n\nincnet.trainable = False\n\nx = incnet.output\nx = layers.AveragePooling2D(pool_size=(5, 5))(x)\nx = layers.Flatten()(x)\nx = layers.Dense(512, activation = \"relu\")(x)\nx = layers.Dropout(0.5)(x)\nprediction = layers.Dense(22, activation='softmax')(x)\n\nmodel = Model(inputs = incnet.input, outputs = prediction)\nmodel.compile(\n    loss = 'categorical_crossentropy',\n    optimizer= 'adam',\n    metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n                   rotation_range = 40,\n                   width_shift_range = 0.2,\n                   height_shift_range = 0.2,\n                   shear_range = 0.2,\n                   zoom_range = 0.2,\n                   horizontal_flip = True)\n\ntrain_generator = train_datagen.flow_from_directory(\n                  BASE_SOURCE_DIR_IMAGES,  \n                  target_size = (target_size, target_size),  \n                  batch_size = 200,\n                  class_mode = 'categorical'\n                 )\n\nvalidation_datagen = ImageDataGenerator(rescale = 1./255)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n                      BASE_SOURCE_DIR_IMAGES_VAL,  \n                      target_size = (target_size, target_size), \n                      batch_size = 200,\n                      class_mode = 'categorical'\n                     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator,\n                     epochs = 5,\n                     verbose = 1,\n                     validation_data = validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#VGG16\n\nvgg16_model = VGG16(input_shape = (300,300,3),\n                  include_top = False,\n                  weights = \"imagenet\")\n\nvgg16_model.trainable = False\n\nx = vgg16_model.output\nx = layers.AveragePooling2D(pool_size = (9,9))(x)\nx = layers.Flatten()(x)\nprediction = layers.Dense(22, activation = \"softmax\")(x)\n\nmodel = Model(vgg16_model.input, prediction)\nmodel.compile(\n    optimizer = \"adam\",\n    loss = \"categorical_crossentropy\",\n    metrics = [\"accuracy\"]\n)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n                   rotation_range = 40,\n                   width_shift_range = 0.2,\n                   height_shift_range = 0.2,\n                   shear_range = 0.2,\n                   zoom_range = 0.2,\n                   horizontal_flip = True)\n\ntrain_generator = train_datagen.flow_from_directory(\n                  BASE_SOURCE_DIR_IMAGES,  \n                  target_size=(300, 300),  \n                  batch_size = 200,\n                  class_mode='categorical'\n                 )\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\n\nvalidation_generator = validation_datagen.flow_from_directory(\n                      BASE_SOURCE_DIR_IMAGES_VAL,  \n                      target_size = (300, 300), \n                      batch_size = 200,\n                      class_mode = 'categorical'\n                     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data = validation_generator,\n    epochs = 5,\n    verbose = 1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Resnet-50\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\nresnet50_model = ResNet50(\n    input_shape = (300, 300, 3),\n    include_top = False,\n    weights = \"imagenet\"\n)\n\nresnet50_model.trainable = False\n\nx = resnet50_model.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(512, activation = \"relu\")(x)\nprediction = layers.Dense(22, activation = \"softmax\")(x)\n\nmodel = Model(resnet50_model.input, prediction)\nmodel.compile(\n    optimizer = \"adam\",\n    loss = \"categorical_crossentropy\",\n    metrics = [\"accuracy\"]\n)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n                   rotation_range = 40,\n                   width_shift_range = 0.2,\n                   height_shift_range = 0.2,\n                   shear_range = 0.2,\n                   zoom_range = 0.2,\n                   horizontal_flip = True)\n\ntrain_generator = train_datagen.flow_from_directory(\n                  BASE_SOURCE_DIR_IMAGES,  \n                  target_size=(300, 300),  \n                  batch_size = 200,\n                  class_mode='categorical'\n                 )\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\n\nvalidation_generator = validation_datagen.flow_from_directory(\n                      BASE_SOURCE_DIR_IMAGES_VAL,  \n                      target_size = (300, 300), \n                      batch_size = 200,\n                      class_mode = 'categorical'\n                     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n    train_generator,\n    epochs = 5,\n    validation_data = validation_generator,\n    verbose = 1\n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}